{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the `requirements.txt` for this course from the workspace of this lab. `File --> Open...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Create Agents to Research and Write an Article\n",
    "\n",
    "In this lesson, you will be introduced to the foundational concepts of multi-agent systems and get an overview of the crewAI framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries are already installed in the classroom. If you're running this notebook on your own machine, you can install the following:\n",
    "```Python\n",
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import from the crewAI libray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a LLM for your agents, you'll be using OpenAI's `gpt-3.5-turbo`.\n",
    "\n",
    "**Optional Note:** crewAI also allow other popular models to be used as a LLM for your Agents. You can see some of the examples at the [bottom of the notebook](#1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_openai_api_key\n",
    "\n",
    "openai_api_key = get_openai_api_key()\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents\n",
    "\n",
    "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
    "- It has been seen that LLMs perform better when they are role playing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent: Planner\n",
    "\n",
    "**Note**: The benefit of using _multiple strings_ :\n",
    "```Python\n",
    "varname = \"line 1 of text\"\n",
    "          \"line 2 of text\"\n",
    "```\n",
    "\n",
    "versus the _triple quote docstring_:\n",
    "```Python\n",
    "varname = \"\"\"line 1 of text\n",
    "             line 2 of text\n",
    "          \"\"\"\n",
    "```\n",
    "is that it can avoid adding those whitespaces and newline characters, making it better formatted to be passed to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Agent in module crewai.agent:\n",
      "\n",
      "class Agent(crewai.agents.agent_builder.base_agent.BaseAgent)\n",
      " |  Agent(*, id: Annotated[uuid.UUID, UuidVersion(uuid_version=4)] = <factory>, formatting_errors: int = 0, role: str, goal: str, backstory: str, config: Optional[Dict[str, Any]] = None, cache: bool = True, verbose: bool = False, max_rpm: Optional[int] = None, allow_delegation: bool = False, tools: Optional[List[Any]] = <factory>, max_iter: int = 25, agent_executor: pydantic.functional_validators.InstanceOf = None, llm: Union[str, Annotated[crewai.llm.LLM, InstanceOf()], Any] = None, crew: Any = None, i18n: crewai.utilities.i18n.I18N = I18N(prompt_file=None), cache_handler: Optional[Annotated[crewai.agents.cache.cache_handler.CacheHandler, InstanceOf()]] = None, tools_handler: Annotated[crewai.agents.tools_handler.ToolsHandler, InstanceOf()] = <factory>, max_tokens: Optional[int] = None, knowledge: Optional[crewai.knowledge.knowledge.Knowledge] = None, knowledge_sources: Optional[List[crewai.knowledge.source.base_knowledge_source.BaseKnowledgeSource]] = None, knowledge_storage: Optional[Any] = None, max_execution_time: Optional[int] = None, agent_ops_agent_name: str = None, agent_ops_agent_id: str = None, step_callback: Optional[Any] = None, use_system_prompt: Optional[bool] = True, function_calling_llm: Union[str, Annotated[crewai.llm.LLM, InstanceOf()], Any, NoneType] = None, system_template: Optional[str] = None, prompt_template: Optional[str] = None, response_template: Optional[str] = None, tools_results: Optional[List[Any]] = [], allow_code_execution: Optional[bool] = False, respect_context_window: bool = True, max_retry_limit: int = 2, multimodal: bool = False, code_execution_mode: Literal['safe', 'unsafe'] = 'safe', embedder: Optional[Dict[str, Any]] = None) -> None\n",
      " |\n",
      " |  Represents an agent in a system.\n",
      " |\n",
      " |  Each agent has a role, a goal, a backstory, and an optional language model (llm).\n",
      " |  The agent can also have memory, can operate in verbose mode, and can delegate tasks to other agents.\n",
      " |\n",
      " |  Attributes:\n",
      " |          agent_executor: An instance of the CrewAgentExecutor class.\n",
      " |          role: The role of the agent.\n",
      " |          goal: The objective of the agent.\n",
      " |          backstory: The backstory of the agent.\n",
      " |          knowledge: The knowledge base of the agent.\n",
      " |          config: Dict representation of agent configuration.\n",
      " |          llm: The language model that will run the agent.\n",
      " |          function_calling_llm: The language model that will handle the tool calling for this agent, it overrides the crew function_calling_llm.\n",
      " |          max_iter: Maximum number of iterations for an agent to execute a task.\n",
      " |          max_rpm: Maximum number of requests per minute for the agent execution to be respected.\n",
      " |          verbose: Whether the agent execution should be in verbose mode.\n",
      " |          allow_delegation: Whether the agent is allowed to delegate tasks to other agents.\n",
      " |          tools: Tools at agents disposal\n",
      " |          step_callback: Callback to be executed after each step of the agent execution.\n",
      " |          knowledge_sources: Knowledge sources for the agent.\n",
      " |          embedder: Embedder configuration for the agent.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Agent\n",
      " |      crewai.agents.agent_builder.base_agent.BaseAgent\n",
      " |      abc.ABC\n",
      " |      pydantic.main.BaseModel\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  create_agent_executor(self, tools: Optional[List[crewai.tools.base_tool.BaseTool]] = None, task=None) -> None\n",
      " |      Create an agent executor for the agent.\n",
      " |\n",
      " |      Returns:\n",
      " |          An instance of the CrewAgentExecutor class.\n",
      " |\n",
      " |  execute_task(self, task: crewai.task.Task, context: Optional[str] = None, tools: Optional[List[crewai.tools.base_tool.BaseTool]] = None) -> str\n",
      " |      Execute a task with the agent.\n",
      " |\n",
      " |      Args:\n",
      " |          task: Task to execute.\n",
      " |          context: Context to execute the task in.\n",
      " |          tools: Tools to use for the task.\n",
      " |\n",
      " |      Returns:\n",
      " |          Output of the agent\n",
      " |\n",
      " |  get_code_execution_tools(self)\n",
      " |\n",
      " |  get_delegation_tools(self, agents: List[crewai.agents.agent_builder.base_agent.BaseAgent])\n",
      " |      Set the task tools that init BaseAgenTools class.\n",
      " |\n",
      " |  get_multimodal_tools(self) -> Sequence[crewai.tools.base_tool.BaseTool]\n",
      " |\n",
      " |  get_output_converter(self, llm, text, model, instructions)\n",
      " |      Get the converter class for the agent to create json/pydantic outputs.\n",
      " |\n",
      " |  model_post_init = wrapped_model_post_init(self: 'BaseModel', context: 'Any', /) -> 'None' from pydantic._internal._model_construction.ModelMetaclass.__new__.<locals>\n",
      " |      We need to both initialize private attributes and call the user-defined model_post_init\n",
      " |      method.\n",
      " |\n",
      " |  post_init_setup(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'_times_executed': <class 'int'>, 'agent_ops_agent_...\n",
      " |\n",
      " |  __class_vars__ = set()\n",
      " |\n",
      " |  __private_attributes__ = {'_logger': ModelPrivateAttr(default=Pydantic...\n",
      " |\n",
      " |  __pydantic_complete__ = True\n",
      " |\n",
      " |  __pydantic_computed_fields__ = {}\n",
      " |\n",
      " |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'pydantic.f...\n",
      " |\n",
      " |  __pydantic_custom_init__ = False\n",
      " |\n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |\n",
      " |  __pydantic_fields__ = {'agent_executor': FieldInfo(annotation=Instance...\n",
      " |\n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |\n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |\n",
      " |  __pydantic_post_init__ = 'model_post_init'\n",
      " |\n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |\n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"Agent\", validator=Func...\n",
      " |\n",
      " |  __signature__ = <Signature (*, id: Annotated[uuid.UUID, UuidVers...bed...\n",
      " |\n",
      " |  model_config = {}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from crewai.agents.agent_builder.base_agent.BaseAgent:\n",
      " |\n",
      " |  __hash__(self, /) from builtins.object\n",
      " |      Return hash(self).\n",
      " |\n",
      " |  copy(self: ~T) -> ~T\n",
      " |      Create a deep copy of the Agent.\n",
      " |\n",
      " |  increment_formatting_errors(self) -> None\n",
      " |\n",
      " |  interpolate_inputs(self, inputs: Dict[str, Any]) -> None\n",
      " |      Interpolate inputs into the agent description and backstory.\n",
      " |\n",
      " |  set_cache_handler(self, cache_handler: crewai.agents.cache.cache_handler.CacheHandler) -> None\n",
      " |      Set the cache handler for the agent.\n",
      " |\n",
      " |      Args:\n",
      " |          cache_handler: An instance of the CacheHandler class.\n",
      " |\n",
      " |  set_private_attrs(self)\n",
      " |      Set private attributes.\n",
      " |\n",
      " |  set_rpm_controller(self, rpm_controller: crewai.utilities.rpm_controller.RPMController) -> None\n",
      " |      Set the rpm controller for the agent.\n",
      " |\n",
      " |      Args:\n",
      " |          rpm_controller: An instance of the RPMController class.\n",
      " |\n",
      " |  validate_and_set_attributes(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from crewai.agents.agent_builder.base_agent.BaseAgent:\n",
      " |\n",
      " |  process_model_config(values)\n",
      " |\n",
      " |  validate_tools(tools: List[Any]) -> List[crewai.tools.base_tool.BaseTool]\n",
      " |      Validate and process the tools provided to the agent.\n",
      " |\n",
      " |      This method ensures that each tool is either an instance of BaseTool\n",
      " |      or an object with 'name', 'func', and 'description' attributes. If the\n",
      " |      tool meets these criteria, it is processed and added to the list of\n",
      " |      tools. Otherwise, a ValueError is raised.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from crewai.agents.agent_builder.base_agent.BaseAgent:\n",
      " |\n",
      " |  key\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from crewai.agents.agent_builder.base_agent.BaseAgent:\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |\n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |\n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |\n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |\n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __init__(self, /, **data: 'Any') -> 'None'\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |\n",
      " |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      " |      validated to form a valid model.\n",
      " |\n",
      " |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      " |\n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |\n",
      " |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |\n",
      " |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      " |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      " |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      " |\n",
      " |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      " |\n",
      " |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |\n",
      " |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      " |      Returns the string representation of a recursive object.\n",
      " |\n",
      " |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      " |\n",
      " |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |\n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |\n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |\n",
      " |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      " |\n",
      " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      " |\n",
      " |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy\n",
      " |\n",
      " |      Returns a copy of the model.\n",
      " |\n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |\n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |\n",
      " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\n",
      " |\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |\n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |\n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |\n",
      " |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json\n",
      " |\n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |\n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      " |\n",
      " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      " |      Hook into generating the model's CoreSchema.\n",
      " |\n",
      " |      Args:\n",
      " |          source: The class we are generating a schema for.\n",
      " |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      " |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      " |\n",
      " |      Returns:\n",
      " |          A `pydantic-core` `CoreSchema`.\n",
      " |\n",
      " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |\n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |\n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called.\n",
      " |\n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |\n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by pydantic.\n",
      " |\n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      " |\n",
      " |  from_orm(obj: 'Any') -> 'Self'\n",
      " |\n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |\n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |\n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |\n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |\n",
      " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      " |      Generates a JSON schema for a model class.\n",
      " |\n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |\n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |\n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |\n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |\n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |\n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |\n",
      " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |\n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |\n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |\n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |\n",
      " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      " |      Validate a pydantic model instance.\n",
      " |\n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |\n",
      " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\n",
      " |\n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |\n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |\n",
      " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |\n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |\n",
      " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      " |\n",
      " |  parse_obj(obj: 'Any') -> 'Self'\n",
      " |\n",
      " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      " |\n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      " |\n",
      " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      " |\n",
      " |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      " |\n",
      " |  validate(value: 'Any') -> 'Self'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __fields_set__\n",
      " |\n",
      " |  model_computed_fields\n",
      " |      Get metadata about the computed fields defined on the model.\n",
      " |\n",
      " |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      " |      In V3, this property will be removed from the `BaseModel` class.\n",
      " |\n",
      " |      Returns:\n",
      " |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n",
      " |\n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |\n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |\n",
      " |  model_fields\n",
      " |      Get metadata about the fields defined on the model.\n",
      " |\n",
      " |      Deprecation warning: you should be getting this information from the model class, not from an instance.\n",
      " |      In V3, this property will be removed from the `BaseModel` class.\n",
      " |\n",
      " |      Returns:\n",
      " |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n",
      " |\n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |\n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __pydantic_extra__\n",
      " |\n",
      " |  __pydantic_fields_set__\n",
      " |\n",
      " |  __pydantic_private__\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __pydantic_root_model__ = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(request=Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "planner = Agent(\n",
    "    role=\"Content Planner\",\n",
    "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
    "    backstory=\"You're working on planning a blog article \"\n",
    "    \"about the topic: {topic}.\"\n",
    "    \"You collect information that helps the \"\n",
    "    \"audience learn something \"\n",
    "    \"and make informed decisions. \"\n",
    "    \"Your work is the basis for \"\n",
    "    \"the Content Writer to write an article on this topic.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent: Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role=\"Content Writer\",\n",
    "    goal=\"Write insightful and factually accurate \"\n",
    "    \"opinion piece about the topic: {topic}\",\n",
    "    backstory=\"You're working on a writing \"\n",
    "    \"a new opinion piece about the topic: {topic}. \"\n",
    "    \"You base your writing on the work of \"\n",
    "    \"the Content Planner, who provides an outline \"\n",
    "    \"and relevant context about the topic. \"\n",
    "    \"You follow the main objectives and \"\n",
    "    \"direction of the outline, \"\n",
    "    \"as provide by the Content Planner. \"\n",
    "    \"You also provide objective and impartial insights \"\n",
    "    \"and back them up with information \"\n",
    "    \"provide by the Content Planner. \"\n",
    "    \"You acknowledge in your opinion piece \"\n",
    "    \"when your statements are opinions \"\n",
    "    \"as opposed to objective statements.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent: Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role=\"Editor\",\n",
    "    goal=\"Edit a given blog post to align with \"\n",
    "    \"the writing style of the organization. \",\n",
    "    backstory=\"You are an editor who receives a blog post \"\n",
    "    \"from the Content Writer. \"\n",
    "    \"Your goal is to review the blog post \"\n",
    "    \"to ensure that it follows journalistic best practices,\"\n",
    "    \"provides balanced viewpoints \"\n",
    "    \"when providing opinions or assertions, \"\n",
    "    \"and also avoids major controversial topics \"\n",
    "    \"or opinions when possible.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tasks\n",
    "\n",
    "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Prioritize the latest trends, key players, \"\n",
    "        \"and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering \"\n",
    "        \"their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including \"\n",
    "        \"an introduction, key points, and a call to action.\\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive content plan document \"\n",
    "    \"with an outline, audience analysis, \"\n",
    "    \"SEO keywords, and resources.\",\n",
    "    agent=planner,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description=(\n",
    "        \"1. Use the content plan to craft a compelling \"\n",
    "        \"blog post on {topic}.\\n\"\n",
    "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
    "        \"3. Sections/Subtitles are properly named \"\n",
    "        \"in an engaging manner.\\n\"\n",
    "        \"4. Ensure the post is structured with an \"\n",
    "        \"engaging introduction, insightful body, \"\n",
    "        \"and a summarizing conclusion.\\n\"\n",
    "        \"5. Proofread for grammatical errors and \"\n",
    "        \"alignment with the brand's voice.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A well-written blog post \"\n",
    "    \"in markdown format, ready for publication, \"\n",
    "    \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description=(\n",
    "        \"Proofread the given blog post for \"\n",
    "        \"grammatical errors and \"\n",
    "        \"alignment with the brand's voice.\"\n",
    "    ),\n",
    "    expected_output=\"A well-written blog post in markdown format, \"\n",
    "    \"ready for publication, \"\n",
    "    \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=editor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crew\n",
    "\n",
    "- Create your crew of Agents\n",
    "- Pass the tasks to be performed by those agents.\n",
    "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
    "- `verbose=2` allows you to see all the logs of the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[planner, writer, editor],\n",
    "    tasks=[plan, write, edit],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**Comprehensive Content Plan Document on Artificial Intelligence**\n",
      "\n",
      "**1. Latest Trends, Key Players, and Noteworthy News on Artificial Intelligence**\n",
      "\n",
      "- **Latest Trends:**\n",
      "  - Generative AI: With models like OpenAI's GPT-3 and ChatGPT, generative AI is becoming integral in content creation, coding, and art.\n",
      "  - AI Ethics and Bias: There's increasing focus on ensuring AI systems are fair and unbiased, with responsible AI development at the forefront.\n",
      "  - AI in Healthcare: AI is being used for diagnostics, treatment recommendations, and predictive analytics in healthcare.\n",
      "  - AI and Automation: Expansion of AI in automating routine tasks across industries leads to greater efficiency and productivity.\n",
      "  - AI and Sustainability: Leveraging AI to address climate change and improve sustainability efforts is gaining traction.\n",
      "\n",
      "- **Key Players:**\n",
      "  - OpenAI\n",
      "  - Google DeepMind\n",
      "  - IBM Watson\n",
      "  - Amazon Web Services (AWS)\n",
      "  - Microsoft AI\n",
      "\n",
      "- **Noteworthy News:**\n",
      "  - The latest updates on regulatory frameworks surrounding AI, such as the EU's AI Act.\n",
      "  - Breakthroughs in AI capabilities, such as improvements in natural language processing (NLP) and computer vision.\n",
      "  - Strategic acquisitions and investments in AI startups by major tech companies like Google, Amazon, and Microsoft.\n",
      "  - Collaborations between healthcare providers and AI companies for disease treatment innovations.\n",
      "\n",
      "**2. Target Audience Analysis:**\n",
      "\n",
      "- **Target Audience:**\n",
      "  - Technology Enthusiasts interested in the latest advancements and ethical implications of AI.\n",
      "  - Business Leaders and Entrepreneurs focusing on adopting AI solutions for enhanced operations and productivity.\n",
      "  - Healthcare Professionals looking for insights on AI applications in diagnostics and patient care.\n",
      "  - Developers and Data Scientists seeking updates on AI tools, frameworks, and development methods.\n",
      "  - Academics and Researchers tracking AI trends for scholarly activities and research opportunities.\n",
      "\n",
      "- **Interests and Pain Points:**\n",
      "  - Interested in practical applications and real-world impact of AI.\n",
      "  - Curious about balancing AI innovation with ethical considerations and data privacy concerns.\n",
      "  - Encountering challenges in integrating AI technologies within existing business systems.\n",
      "  - Concerned about the job market shift due to AI-driven automation.\n",
      "  \n",
      "**3. Detailed Content Outline:**\n",
      "\n",
      "- **Introduction:**\n",
      "  - Define Artificial Intelligence and its significance in the modern world.\n",
      "  - Briefly introduce the growing influence of AI across various domains.\n",
      "\n",
      "- **Key Points:**\n",
      "  1. **AI Trends Transforming Industries:**\n",
      "     - Explore each of the latest AI trends like Generative AI, AI Ethics, and AI in Healthcare, providing examples and potential applications.\n",
      "  \n",
      "  2. **Leading Companies and Innovations:**\n",
      "     - Discuss contributions of key players such as OpenAI, Google DeepMind, etc., highlighting their impact on the AI landscape.\n",
      "  \n",
      "  3. **Challenges and Ethical Considerations:**\n",
      "     - Dive into challenges like AI bias, data privacy concerns, and the need for responsible AI-use frameworks.\n",
      "  \n",
      "  4. **Future of AI and Human Workforce:**\n",
      "     - Analyze implications of AI-driven automation on employment and skill requirements.\n",
      "  \n",
      "  5. **AI in Sustainability:**\n",
      "     - Examine how AI is being used to promote sustainability and combat climate change.\n",
      "  \n",
      "- **Call to Action:**\n",
      "  - Encourage readers to stay informed about AI advancements and consider embracing AI solutions for growth and efficiency.\n",
      "  - Invite readers to subscribe for regular updates and deeper analysis on AI and emerging technologies.\n",
      "\n",
      "**4. SEO Keywords and Resources:**\n",
      "\n",
      "- **SEO Keywords:**\n",
      "  - Artificial Intelligence Trends 2023\n",
      "  - AI in Healthcare\n",
      "  - Ethical AI Development\n",
      "  - AI and Automation\n",
      "  - Generative AI Examples\n",
      "\n",
      "- **Relevant Data or Sources:**\n",
      "  - McKinsey & Company's reports on AI and industry applications.\n",
      "  - Research articles from AI-focused journals like the Journal of Artificial Intelligence Research (JAIR).\n",
      "  - Blogs or updates from leading AI companies: OpenAI, Google AI Blog, Microsoft AI and Research. \n",
      "\n",
      "This comprehensive content plan provides a structured approach for developing an engaging and insightful article covering the latest in Artificial Intelligence.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Use the content plan to craft a compelling blog post on Artificial Intelligence.\n",
      "2. Incorporate SEO keywords naturally.\n",
      "3. Sections/Subtitles are properly named in an engaging manner.\n",
      "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "```markdown\n",
      "# Navigating the Future with Artificial Intelligence: Trends, Innovations, and Ethical Imperatives\n",
      "\n",
      "Artificial Intelligence (AI) stands as a transformative force in the modern world, reshaping industries and everyday experiences alike. From AI-driven chatbots orchestrating customer interactions to sophisticated algorithms diagnosing complex health conditions, AI's influence knows no bounds. This technological marvel has rapidly woven itself into the fabric of contemporary society, heralding a new era of innovation and efficiency across diverse sectors.\n",
      "\n",
      "In recent years, AI's scope and capabilities have expanded dramatically. Key players like OpenAI and Google DeepMind drive groundbreaking research and innovations, setting the stage for an AI-powered future. This piece delves into the latest trends in AI, explores the contributions of leading companies, examines the challenges and ethical debates surrounding AI, and ponders its future impact on the workforce and sustainability efforts.\n",
      "\n",
      "## AI Trends Transforming Industries\n",
      "\n",
      "One of the most captivating trends today is Generative AI, which is making significant strides in fields such as content creation, coding, and digital art. Tools like OpenAI's GPT-3 and ChatGPT facilitate seamless interaction between machines and humans, opening new horizons for creativity and productivity. For instance, these AI models are employed to draft articles, produce music, and even generate code, offering a glimpse into a world where AI assists in human endeavors with unprecedented precision.\n",
      "\n",
      "In parallel, the ethical implications of AI have commanded attention. Ensuring fairness and mitigating bias in AI systems are critical. Organizations are investing in responsible AI development to address concerns such as data privacy and algorithmic discrimination. Striking a balance between innovation and ethical considerations is imperative to foster trust and acceptance of AI technologies.\n",
      "\n",
      "Moreover, AI's integration into healthcare promises transformative benefits. From aiding diagnostics through predictive analytics to offering personalized treatment recommendations, AI is revolutionizing patient care. Its potential to streamline healthcare processes heralds a future where AI enhances both accuracy and efficiency, ultimately improving clinical outcomes.\n",
      "\n",
      "## Leading Companies and Innovations\n",
      "\n",
      "Top-tier organizations like OpenAI, Google DeepMind, IBM Watson, Amazon Web Services, and Microsoft AI are at the forefront of AI advancement. Their contributions significantly shape the technology's trajectory, influencing AI's role across various domains. OpenAI's innovations in natural language processing, for instance, are redefining human-machine interactions, while Google DeepMind's focus on machine learning and neural networks pushes the envelope of what's possible with AI.\n",
      "\n",
      "These companies not only pioneer research but also engage in strategic acquisitions and investments in AI startups, signaling a robust commitment to building a future dominated by AI technologies. Collaborative initiatives, especially in healthcare, spearhead breakthroughs that could redefine how diseases are treated and managed, epitomizing the symbiotic relationship between tech giants and the health sector.\n",
      "\n",
      "## Challenges and Ethical Considerations\n",
      "\n",
      "Despite AI's promise, it is not without its challenges. AI bias remains an omnipresent concern, potentially leading to unequal outcomes across different user demographics. As AI systems increasingly infiltrate decision-making processes, maintaining data privacy and ensuring ethical use of AI become paramount. Frameworks like the EU's AI Act aim to establish regulations that govern AI development responsibly, ensuring these systems uphold human values and rights.\n",
      "\n",
      "The ethical debate extends to the ownership and usage of data. As AI systems consume vast amounts of information to learn and improve, the infringement of personal privacy becomes a critical point of discussion. Organizations must transparently navigate these issues, creating AI systems that are both ethical and effective.\n",
      "\n",
      "## Future of AI and Human Workforce\n",
      "\n",
      "AI's rapid advancement inevitably raises questions about its impact on employment and required skills. As automation becomes more prevalent, industries may witness a fundamental shift in the job market. While AI can enhance productivity and streamline operations, it may also displace certain roles, prompting a reevaluation of workforce dynamics.\n",
      "\n",
      "However, this evolution also presents opportunities. New roles focused on AI oversight, ethical management, and technological integration will arise, requiring an upskilled workforce ready to adapt to and leverage AI-driven environments. As AI transforms industries, continuous learning and adaptability will remain essential for individuals and companies alike.\n",
      "\n",
      "## AI in Sustainability\n",
      "\n",
      "Harnessing AI for sustainability is a promising frontier. From optimizing energy consumption to predicting environmental changes, AI is pivotal in tackling climate change. Through intelligent systems that enhance resource management and reduce waste, AI contributes to a more sustainable future. Companies are increasingly investing in AI solutions geared towards sustainability, showcasing AI's potential as a catalyst for environmental stewardship and innovation.\n",
      "\n",
      "## Concluding Thoughts\n",
      "\n",
      "The rapid evolution of Artificial Intelligence presents a landscape teeming with opportunities and challenges. As AI continues to redefine sectors and redefine possibilities, staying informed and engaged with these advancements is crucial. Embracing AI not only enhances productivity and innovation but also demands a conscientious approach to ethics and sustainability. \n",
      "\n",
      "As we chart the course of AI's future, let us commit to fostering an ecosystem where technology serves humanity, aligns with ethical values, and promotes a sustainable world. We invite you to subscribe to our channel for ongoing updates and comprehensive analyses on AI and its burgeoning influence in the digital realm.\n",
      "```\n",
      "\n",
      "This well-structured blog post integrates SEO keywords like \"Artificial Intelligence Trends 2023,\" \"AI in Healthcare,\" and \"Ethical AI Development\" naturally throughout the text, meeting the described criteria for an engaging piece.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "```markdown\n",
      "# Navigating the Future with Artificial Intelligence: Trends, Innovations, and Ethical Imperatives\n",
      "\n",
      "Artificial Intelligence (AI) stands as a transformative force in the modern world, reshaping industries and everyday experiences alike. From AI-driven chatbots orchestrating customer interactions to sophisticated algorithms diagnosing complex health conditions, AI's influence knows no bounds. This technological marvel has rapidly woven itself into the fabric of contemporary society, heralding a new era of innovation and efficiency across diverse sectors.\n",
      "\n",
      "In recent years, AI's scope and capabilities have expanded dramatically. Key players like OpenAI and Google DeepMind drive groundbreaking research and innovations, setting the stage for an AI-powered future. This piece delves into the latest trends in AI, explores the contributions of leading companies, examines the challenges and ethical debates surrounding AI, and ponders its future impact on the workforce and sustainability efforts.\n",
      "\n",
      "## AI Trends Transforming Industries\n",
      "\n",
      "One of the most captivating trends today is Generative AI, which is making significant strides in fields such as content creation, coding, and digital art. Tools like OpenAI's GPT-3 and ChatGPT facilitate seamless interaction between machines and humans, opening new horizons for creativity and productivity. For instance, these AI models are employed to draft articles, produce music, and even generate code, offering a glimpse into a world where AI assists in human endeavors with unprecedented precision.\n",
      "\n",
      "In parallel, the ethical implications of AI have commanded attention. Ensuring fairness and mitigating bias in AI systems are critical. Organizations are investing in responsible AI development to address concerns such as data privacy and algorithmic discrimination. Striking a balance between innovation and ethical considerations is imperative to foster trust and acceptance of AI technologies.\n",
      "\n",
      "Moreover, AI's integration into healthcare promises transformative benefits. From aiding diagnostics through predictive analytics to offering personalized treatment recommendations, AI is revolutionizing patient care. Its potential to streamline healthcare processes heralds a future where AI enhances both accuracy and efficiency, ultimately improving clinical outcomes.\n",
      "\n",
      "## Leading Companies and Innovations\n",
      "\n",
      "Top-tier organizations like OpenAI, Google DeepMind, IBM Watson, Amazon Web Services, and Microsoft AI are at the forefront of AI advancement. Their contributions significantly shape the technology's trajectory, influencing AI's role across various domains. OpenAI's innovations in natural language processing, for instance, are redefining human-machine interactions, while Google DeepMind's focus on machine learning and neural networks pushes the envelope of what's possible with AI.\n",
      "\n",
      "These companies not only pioneer research but also engage in strategic acquisitions and investments in AI startups, signaling a robust commitment to building a future dominated by AI technologies. Collaborative initiatives, especially in healthcare, spearhead breakthroughs that could redefine how diseases are treated and managed, epitomizing the symbiotic relationship between tech giants and the health sector.\n",
      "\n",
      "## Challenges and Ethical Considerations\n",
      "\n",
      "Despite AI's promise, it is not without its challenges. AI bias remains an omnipresent concern, potentially leading to unequal outcomes across different user demographics. As AI systems increasingly infiltrate decision-making processes, maintaining data privacy and ensuring ethical use of AI become paramount. Frameworks like the EU's AI Act aim to establish regulations that govern AI development responsibly, ensuring these systems uphold human values and rights.\n",
      "\n",
      "The ethical debate extends to the ownership and usage of data. As AI systems consume vast amounts of information to learn and improve, the infringement of personal privacy becomes a critical point of discussion. Organizations must transparently navigate these issues, creating AI systems that are both ethical and effective.\n",
      "\n",
      "## Future of AI and Human Workforce\n",
      "\n",
      "AI's rapid advancement inevitably raises questions about its impact on employment and required skills. As automation becomes more prevalent, industries may witness a fundamental shift in the job market. While AI can enhance productivity and streamline operations, it may also displace certain roles, prompting a reevaluation of workforce dynamics.\n",
      "\n",
      "However, this evolution also presents opportunities. New roles focused on AI oversight, ethical management, and technological integration will arise, requiring an upskilled workforce ready to adapt to and leverage AI-driven environments. As AI transforms industries, continuous learning and adaptability will remain essential for individuals and companies alike.\n",
      "\n",
      "## AI in Sustainability\n",
      "\n",
      "Harnessing AI for sustainability is a promising frontier. From optimizing energy consumption to predicting environmental changes, AI is pivotal in tackling climate change. Through intelligent systems that enhance resource management and reduce waste, AI contributes to a more sustainable future. Companies are increasingly investing in AI solutions geared towards sustainability, showcasing AI's potential as a catalyst for environmental stewardship and innovation.\n",
      "\n",
      "## Concluding Thoughts\n",
      "\n",
      "The rapid evolution of Artificial Intelligence presents a landscape teeming with opportunities and challenges. As AI continues to redefine sectors and redefine possibilities, staying informed and engaged with these advancements is crucial. Embracing AI not only enhances productivity and innovation but also demands a conscientious approach to ethics and sustainability. \n",
      "\n",
      "As we chart the course of AI's future, let us commit to fostering an ecosystem where technology serves humanity, aligns with ethical values, and promotes a sustainable world. We invite you to subscribe to our channel for ongoing updates and comprehensive analyses on AI and its burgeoning influence in the digital realm.\n",
      "```\n",
      "\n",
      "This well-structured blog post integrates SEO keywords like \"Artificial Intelligence Trends 2023,\" \"AI in Healthcare,\" and \"Ethical AI Development\" naturally throughout the text, meeting the described criteria for an engaging piece.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the results of your execution as markdown in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Navigating the Future with Artificial Intelligence: Trends, Innovations, and Ethical Imperatives\n",
       "\n",
       "Artificial Intelligence (AI) stands as a transformative force in the modern world, reshaping industries and everyday experiences alike. From AI-driven chatbots orchestrating customer interactions to sophisticated algorithms diagnosing complex health conditions, AI's influence knows no bounds. This technological marvel has rapidly woven itself into the fabric of contemporary society, heralding a new era of innovation and efficiency across diverse sectors.\n",
       "\n",
       "In recent years, AI's scope and capabilities have expanded dramatically. Key players like OpenAI and Google DeepMind drive groundbreaking research and innovations, setting the stage for an AI-powered future. This piece delves into the latest trends in AI, explores the contributions of leading companies, examines the challenges and ethical debates surrounding AI, and ponders its future impact on the workforce and sustainability efforts.\n",
       "\n",
       "## AI Trends Transforming Industries\n",
       "\n",
       "One of the most captivating trends today is Generative AI, which is making significant strides in fields such as content creation, coding, and digital art. Tools like OpenAI's GPT-3 and ChatGPT facilitate seamless interaction between machines and humans, opening new horizons for creativity and productivity. For instance, these AI models are employed to draft articles, produce music, and even generate code, offering a glimpse into a world where AI assists in human endeavors with unprecedented precision.\n",
       "\n",
       "In parallel, the ethical implications of AI have commanded attention. Ensuring fairness and mitigating bias in AI systems are critical. Organizations are investing in responsible AI development to address concerns such as data privacy and algorithmic discrimination. Striking a balance between innovation and ethical considerations is imperative to foster trust and acceptance of AI technologies.\n",
       "\n",
       "Moreover, AI's integration into healthcare promises transformative benefits. From aiding diagnostics through predictive analytics to offering personalized treatment recommendations, AI is revolutionizing patient care. Its potential to streamline healthcare processes heralds a future where AI enhances both accuracy and efficiency, ultimately improving clinical outcomes.\n",
       "\n",
       "## Leading Companies and Innovations\n",
       "\n",
       "Top-tier organizations like OpenAI, Google DeepMind, IBM Watson, Amazon Web Services, and Microsoft AI are at the forefront of AI advancement. Their contributions significantly shape the technology's trajectory, influencing AI's role across various domains. OpenAI's innovations in natural language processing, for instance, are redefining human-machine interactions, while Google DeepMind's focus on machine learning and neural networks pushes the envelope of what's possible with AI.\n",
       "\n",
       "These companies not only pioneer research but also engage in strategic acquisitions and investments in AI startups, signaling a robust commitment to building a future dominated by AI technologies. Collaborative initiatives, especially in healthcare, spearhead breakthroughs that could redefine how diseases are treated and managed, epitomizing the symbiotic relationship between tech giants and the health sector.\n",
       "\n",
       "## Challenges and Ethical Considerations\n",
       "\n",
       "Despite AI's promise, it is not without its challenges. AI bias remains an omnipresent concern, potentially leading to unequal outcomes across different user demographics. As AI systems increasingly infiltrate decision-making processes, maintaining data privacy and ensuring ethical use of AI become paramount. Frameworks like the EU's AI Act aim to establish regulations that govern AI development responsibly, ensuring these systems uphold human values and rights.\n",
       "\n",
       "The ethical debate extends to the ownership and usage of data. As AI systems consume vast amounts of information to learn and improve, the infringement of personal privacy becomes a critical point of discussion. Organizations must transparently navigate these issues, creating AI systems that are both ethical and effective.\n",
       "\n",
       "## Future of AI and Human Workforce\n",
       "\n",
       "AI's rapid advancement inevitably raises questions about its impact on employment and required skills. As automation becomes more prevalent, industries may witness a fundamental shift in the job market. While AI can enhance productivity and streamline operations, it may also displace certain roles, prompting a reevaluation of workforce dynamics.\n",
       "\n",
       "However, this evolution also presents opportunities. New roles focused on AI oversight, ethical management, and technological integration will arise, requiring an upskilled workforce ready to adapt to and leverage AI-driven environments. As AI transforms industries, continuous learning and adaptability will remain essential for individuals and companies alike.\n",
       "\n",
       "## AI in Sustainability\n",
       "\n",
       "Harnessing AI for sustainability is a promising frontier. From optimizing energy consumption to predicting environmental changes, AI is pivotal in tackling climate change. Through intelligent systems that enhance resource management and reduce waste, AI contributes to a more sustainable future. Companies are increasingly investing in AI solutions geared towards sustainability, showcasing AI's potential as a catalyst for environmental stewardship and innovation.\n",
       "\n",
       "## Concluding Thoughts\n",
       "\n",
       "The rapid evolution of Artificial Intelligence presents a landscape teeming with opportunities and challenges. As AI continues to redefine sectors and redefine possibilities, staying informed and engaged with these advancements is crucial. Embracing AI not only enhances productivity and innovation but also demands a conscientious approach to ethics and sustainability. \n",
       "\n",
       "As we chart the course of AI's future, let us commit to fostering an ecosystem where technology serves humanity, aligns with ethical values, and promotes a sustainable world. We invite you to subscribe to our channel for ongoing updates and comprehensive analyses on AI and its burgeoning influence in the digital realm.\n",
       "```\n",
       "\n",
       "This well-structured blog post integrates SEO keywords like \"Artificial Intelligence Trends 2023,\" \"AI in Healthcare,\" and \"Ethical AI Development\" naturally throughout the text, meeting the described criteria for an engaging piece."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(data=result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it Yourself\n",
    "\n",
    "- Pass in a topic of your choice and see what the agents come up with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "topic = \"YOUR TOPIC HERE\"\n",
    "result = crew.kickoff(inputs={\"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    " ## Other Popular Models as LLM for your Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face (HuggingFaceHub endpoint)\n",
    "\n",
    "```Python\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    huggingfacehub_api_token=\"<HF_TOKEN_HERE>\",\n",
    "    task=\"text-generation\",\n",
    ")\n",
    "\n",
    "### you will pass \"llm\" to your agent function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral API\n",
    "\n",
    "```Python\n",
    "OPENAI_API_KEY=your-mistral-api-key\n",
    "OPENAI_API_BASE=https://api.mistral.ai/v1\n",
    "OPENAI_MODEL_NAME=\"mistral-small\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohere\n",
    "\n",
    "```Python\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "# Initialize language model\n",
    "os.environ[\"COHERE_API_KEY\"] = \"your-cohere-api-key\"\n",
    "llm = ChatCohere()\n",
    "\n",
    "### you will pass \"llm\" to your agent function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For using Llama locally with Ollama and more, checkout the crewAI documentation on [Connecting to any LLM](https://docs.crewai.com/how-to/LLM-Connections/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "agents-tutorial-lffBnLp0-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
